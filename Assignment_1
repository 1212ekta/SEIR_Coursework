import sys #for command line argument
import requests    #for get request
from bs4 import BeautifulSoup #web scraping

def web_url():  # function for detecting url on command line
    if len(sys.argv) < 2:
        print("Argument is None, please provide it")
        sys.exit()
    else:
        link = sys.argv[1]
        if not link.startswith("http"):  # check secured url
            print("Not an authentic url")
            sys.exit()
    return link

def retreive_page(link):  # function for fetching the page by url
    try:
        headers = {"User-Agent": "Mozilla/5.0"}  # request as browser
        server_response = requests.get(link, headers=headers)
    except requests.exceptions.RequestException as e:
        print("Error while fetching page:", e)
        sys.exit()

    if server_response.status_code != 200: #if there is something wrong ,if everything is ok then the code is 200
        print("Not able to fetch the page")
        sys.exit()

    return server_response.text

def page_html(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    return soup

def page_title(doc):
    if doc.title and doc.title.string:
        return doc.title.string.strip()
    else:
        return "No title found"

def retreive_body(doc):
    if doc.body:
        visible_text = doc.body.get_text(separator="\n", strip=True)#strip revome the trailing spaces of the content
        if visible_text:
            return visible_text
        else:
            return "Either not in readable form or content not found"
    return "No body found"

def page_links(doc):
    store_link = []
    anchor_links = doc.find_all("a")
    for link in anchor_links:
        hyperlink_ref = link.get("href")
        if hyperlink_ref:
            store_link.append(hyperlink_ref)
    return store_link

def main():
    link = web_url()
    html_content = retreive_page(link)
    doc = page_html(html_content)

    all_title = page_title(soup)
    body_text = retreive_body(soup)
    all_links = page_links(soup)

    print("\nPage Title:")
    print(all_title)
    print("\nPage Body:")
    print(body_text)
    print("\nAll Links:")
    if all_links:
        for link in all_links:
            print(link)
    else:
        print("No links found")
if __name__ == "__main__":
    main()
